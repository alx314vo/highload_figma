# Figma
## **1. Тема и целевая аудитория**

### **Тип сервиса**
Веб-приложение для коллаборативного UI/UX-дизайна (SaaS).  
**Аналоги:** Sketch, Adobe XD.  
**Рыночная ниша:** 40.65% доли рынка дизайнерских инструментов [SQ Magazine].


### Функционал MVP

1.  **Создание и редактирование векторного дизайна в браузере.**
2.  **Реалтайм-коллаборация** (одновременное редактирование с видимостью курсоров).
3.  **Комментирование** (привязка комментариев к элементам).
4.  **Developer Handoff** (экспорт CSS/SVG, отображение отступов).


### **Продуктовые решения**

*   **Клиент — веб-приложение** .
*   **Коллаборация в реальном времени.**
*   **Хранение истории версий** .
*   **Разделение прав доступа** (владелец, редактор, зритель).
*   **Интеграция ИИ** (agentic AI — 51% пользователей Figma) [Figma Blog].



### **Целевая аудитория**

| Параметр | Значение | Источник |
|----------|----------|----------|
| **MAU** | 13,000,000 | [SQ Magazine] |
| **DAU** | 4,300,000 (оценка: 1/3 от MAU) | Расчет на основе [SQ Magazine] |
| **География** | 38% — США, 6% — Великобритания, 7% — Индия, 49% — остальные (включая Россию ~15%) | [Enlyft] |
| **Количество компаний-пользователей** | 67,681 | [Enlyft] |
| **Проникновение в Fortune 500** | 95% | [SQ Magazine] |


## **2. Расчет нагрузки**

### **Продуктовые метрики**

| Метрика | Значение | Источник |
|---------|----------|------------------------|
| **Среднее количество сессий на пользователя в день** | 1.5 | Оценка на основе типичного рабочего дня |
| **Средняя длительность сессии** | 50 минут | [SQ Magazine]: 16 мин 7 сек на сайте → 3x для активной работы в приложении |
| **Среднее количество операций на пользователя в час** | 150 | Оценка на основе активности дизайнера (рисование, перемещение, группировка) |
| **Средний размер файла** | 8 МБ | Оценка на основе сложности проектов |
| **Среднее количество файлов на пользователя** | 20 | Оценка на основе активности |


### **Технические метрики**

#### **Объем хранилища**

| Тип данных | Кол-во объектов | Средний размер | Общий объем |
|------------|-----------------|----------------|-------------|
| **Дизайн-файлы** | 260,000,000 | 8 МБ | **2,080 ТБ** |
| **История версий (10 версий/файл)** | 2,600,000,000 | 2 МБ | **5,200 ТБ** |
| **Комментарии (50 на файл)** | 13,000,000,000 | 1 КБ | **13 ТБ** |
| **Аватарки/настройки пользователей** | 13,000,000 | 1 МБ | **13 ТБ** |
| **ИТОГО** | — | — | **~7,300 ТБ (7.3 ПБ)** |


#### **Сетевой трафик**

| Тип трафика | Среднее значение (ГБ/день) | Пиковое значение (Гбит/с) |
|-------------|-----------------------------|----------------------------|
| **Загрузка файлов (чтение)** | 103,200 | — |
| **Выгрузка изменений (запись)** | 8,062.5 | — |
| **Broadcast изменений** | 20,156.25 | — |
| **ИТОГО исходящий трафик** | **131,419 ГБ/день (131 ТБ/день)** | **~110 Гбит/с** (пиковое) |


#### **RPS (Requests Per Second)**

| Тип запроса | Средний RPS | Пиковый RPS (x3) |
|-------------|-------------|------------------|
| **GET /file/{id}** (открытие файла) | 149 | 447 |
| **POST /operation** (сохранение операции) | 9,323 | 27,969 |
| **WebSocket push** (broadcast изменений) | 23,308 | 69,924 |
| **GET /files** (список файлов) | 149 | 447 |
| **POST /comment** (добавление комментария) | 372 | 1,116 |
| **ИТОГО** | **~33,301 RPS** | **~99,903 RPS** |


## **3. Глобальная балансировка нагрузки**

**3.1. Обоснование расположения ДЦ**

Главная задача — сделать так, чтобы приложение не лагало при работе из любой точки мира, так как это напрямую влияет на основные метрики:

*   **Для удержания пользователей:** Низкая задержка критична для редактора и коллаборации. Если курсор коллеги двигается с задержкой или элементы рисуются медленно, пользователи будут недовольны и могут уйти. Исследования показывают, что задержка >100 мс в реалтайм-приложениях приводит к снижению вовлеченности на 20-30%.

*   **Для повышения вовлеченности:** Быстрая загрузка файлов и отклик интерфейса увеличивают время сессии и активность. Задержка загрузки файла приводит к потере пользователей.

**Архитектурное решение:** Распределение ДЦ по регионам с максимальной концентрацией пользователей минимизирует сетевую задержку. 

**Принцип размещения:**
- **Приложение размещается близко к базе данных** — это дает низкую задержку при чтении/записи в БД
- **Файлы (борды) размещаются близко к пользователю** — это дает быструю загрузку больших файлов

Поэтому используем следующую архитектуру:

*   **Основная база данных в Санкт-Петербурге (Россия):** PostgreSQL с метаданными файлов, пользователей, проектов. Здесь же приложения для работы с базой.
*   **Центральный сервер в Нью-Йорке (США):** Авторизация, создание файлов (бордов), управление проектами. Мастер-нода PostgreSQL для записи метаданных.
*   **Региональные ДЦ для редактирования:**
  - **Нью-Йорк (США):** 38% пользователей — редактирование файлов
  - **Франкфурт (Европа):** ~20% пользователей — редактирование файлов  
  - **Санкт-Петербург (Россия):** ~15% пользователей — редактирование файлов
*   **CDN (глобальная сеть):** Статика (JS/CSS), превью файлов, ассеты — раздаются из ближайших edge-серверов по всему миру

**3.2. Распределение нагрузки по ДЦ**

| Тип запроса | Нью-Йорк (мастер) | Нью-Йорк (редактирование) | Франкфурт (редактирование) | СПб (редактирование) | СПб (БД) |
|-------------|-------------------|---------------------------|---------------------------|----------------------|----------|
| **Авторизация, создание файлов** | 50 | — | — | — | — |
| **GET /file/{id}** (447 RPS) | — | 170 | 135 | 142 | — |
| **POST /operation** (27,969 RPS) | — | 10,625 | 8,400 | 8,944 | — |
| **WebSocket push** (69,924 RPS) | — | 26,570 | 21,000 | 22,354 | — |
| **GET /files** (447 RPS) | — | 170 | 135 | 142 | — |
| **Чтение/запись БД** | — | — | — | — | 1,200 |
| **ИТОГО** | **50 RPS** | **37,535 RPS** | **29,670 RPS** | **31,582 RPS** | **1,200 QPS** |

> Распределение сделано пропорционально географии: США 38%, Европа ~20%, Россия ~15%, остальные ~27%. Редактирование происходит в региональных ДЦ, чтение/запись БД — в СПб.

**3.3. Схема глобальной балансировки**

**CDN (Cloudflare / AWS CloudFront):**
- Статика (JS/CSS бандлы, ассеты, превью) отдается из ближайших edge-серверов по всему миру
- Защита от DDoS на уровне CDN
- TTL для статики: 24 часа

**Geo-Based DNS:**
- Пользователи из США → `figma.com` → Нью-Йорк (редактирование)
- Пользователи из Европы → `figma.com` → Франкфурт (редактирование)  
- Пользователи из России → `figma.com` → Санкт-Петербург (редактирование)
- Авторизация и создание файлов → Нью-Йорк (мастер)
- Чтение/запись БД → Санкт-Петербург (основная БД)

**3.4. Механизм регулировки трафика между ДЦ**

**Принцип работы:**

1. **Авторизация и создание файлов** → Нью-Йорк (мастер-сервер)
   - Все новые файлы создаются здесь
   - Метаданные записываются в PostgreSQL мастер в Нью-Йорке
   - Затем реплицируются в СПб (основная БД)

2. **Редактирование файлов** → ближайший региональный ДЦ
   - Операции редактирования записываются в Cassandra локально в регионе
   - Это дает задержку <5 мс вместо 50-150 мс при записи в удаленный регион
   - Асинхронная репликация между регионами обеспечивает синхронизацию

3. **Чтение/запись БД** → Санкт-Петербург
   - Приложения для работы с БД размещены в СПб рядом с базой
   - Это дает низкую задержку при запросах к PostgreSQL
   - Региональные сервисы редактирования обращаются к БД в СПб через сеть

4. **Загрузка файлов** → ближайший региональный ДЦ + CDN
   - Файлы хранятся в Ceph в каждом регионе
   - Превью и статика отдаются через CDN из edge-серверов



## **4. Локальная балансировка нагрузки**

### **4.1. Схема балансировки**

После попадания пользователя в региональный ДЦ через Geo-Based DNS, запрос обрабатывается следующим образом:

1. **CDN** (глобальная балансировка):
   - Статика (JS/CSS бандлы, ассеты, превью) отдается из ближайших edge-серверов
   - Защита от DDoS на уровне CDN
   - Если статика не в кэше CDN, запрос идет на L7-балансировщик

2. **L7-балансировщик** (NGINX):
   - Принимаем трафик сразу на L7 (без L4), так как NGINX справляется с нагрузкой
   - Распределяет запросы по backend-сервисам:
     - Least Connections для WebSocket-соединений
     - Round Robin для обычных HTTP-запросов
   - Кэширует метаданные файлов
   - Формула резервирования: N+1 


### **4.2. Расчет количества балансировщиков (на примере Москвы)**

**Допущения:**
- Один NGINX L7-инстанс способен обрабатывать **8,000 RPS** (с учетом SSL termination и кэширования)
- Целевая загрузка: **70%** (U = 0.7)
- Запас на всплески: **30%** (S = 1.3) — это разница между целевой загрузкой 70% и максимальной 100%

**Расчет для L7-балансировщиков (на примере Нью-Йорка):**

Формула: `N = ⌈(RPS_пик × S) / (RPS_балансировщика × U)⌉`

Подстановка значений:
- RPS_пик = 37,535 (Нью-Йорк, редактирование)
- S = 1.3 (запас 30%)
- RPS_балансировщика = 8,000
- U = 0.7 (целевая загрузка 70%)

Расчет: `N = ⌈(37,535 × 1.3) / (8,000 × 0.7)⌉ = ⌈48,796 / 5,600⌉ = ⌈8.71⌉ = 9`

С учетом отказоустойчивости и распределения по 3 зонам доступности: **12 инстансов NGINX L7** (4 в каждой AZ).

**Примечание:** L4-балансировщик не используется, так как принимаем трафик сразу на L7.



## **5. Логическая схема БД**

![Логическая схема БД](db-logical.png)

| Таблица | Назначение |
|---------|------------|
| **users** | Хранение данных пользователей, аутентификация |
| **teams** | Команды/организации пользователей |
| **team_members** | Связь пользователей с командами и ролями |
| **projects** | Проекты (контейнеры для файлов) |
| **files** | Метаданные дизайн-файлов (бордов) |
| **document_body** | Тело документа в формате YAML — структура элементов холста |
| **document_resources** | Ресурсы документа (изображения, шрифты, иконки) — ссылки на файлы в Object Storage |
| **document_diffs** | Дифы (изменения) документа — аналогично git, хранятся последовательно |
| **document_snapshots** | Снапшоты (снимки состояния) документа по ID транзакции — для быстрого восстановления |
| **document_transactions** | Транзакции (ID транзакции, ссылка на снапшот, список дифов) — для определения точки применения дифов |
| **file_access** | Права доступа к файлам (владелец, редактор, зритель) |
| **operations** | Операции редактирования и комментарии (объединены) — для синхронизации и коллаборации |
| **static_assets** | Статика (JS/CSS бандлы, ассеты) — метаданные для CDN |
| **user_sessions** | Активные сессии пользователей |

### **Как устроен документ (файл/борд)**

Документ хранится по модели, похожей на git:

1. **Снапшот (snapshot)** — полное состояние документа в формате YAML на момент транзакции
   - Создается периодически (например, каждые 100 операций или раз в час)
   - Хранится в Object Storage (Ceph)
   - Имеет ID транзакции, относительно которой можно применять дифы

2. **Дифы (diffs)** — последовательность изменений относительно снапшота
   - Каждый диф содержит: ID транзакции, тип операции (добавить/удалить/изменить элемент), данные операции
   - Хранятся в Cassandra последовательно
   - Применяются к снапшоту для получения актуального состояния

3. **Транзакции** — связывают снапшот и дифы
   - ID транзакции определяет точку относительно снапшота
   - Позволяет точно определить, с какой позиции накатывать дифы
   - Решает проблему конфликтов при одновременном редактировании

**Пример:** 
- Снапшот на транзакции #1000 (состояние документа на момент 1000-й операции)
- Дифы с транзакции #1001 до #1050 (50 изменений)
- Чтобы получить актуальное состояние: берем снапшот #1000 + применяем все дифы с #1001 до текущей транзакции

### **Размеры таблиц и QPS**

| Название таблицы | Расчеты | Итог | Количество строк | Нагрузка на запись (QPS) | Нагрузка на чтение (QPS) |
|------------------|---------|------|------------------|--------------------------|--------------------------|
| **users** | Состав: ID(8) + Email(100) + PasswordHash(60) + Name(100) + AvatarURL(200) + CreatedAt/UpdatedAt(16) = **≈484 B**<br>Количество: 13,000,000 пользователей | **≈6.3 ГБ** | **13,000,000** | **5** (регистрация) | **50** (авторизация, профили) |
| **teams** | Состав: ID(8) + Name(200) + OwnerID(8) + CreatedAt/UpdatedAt(16) = **≈232 B**<br>Количество: 67,681 команд | **≈15 МБ** | **67,681** | **1** | **10** |
| **team_members** | Состав: TeamID(8) + UserID(8) + Role(20) + CreatedAt(8) = **≈44 B**<br>Количество: 13M × 1.5 = **19,500,000** | **≈858 МБ** | **19,500,000** | **10** | **20** |
| **projects** | Состав: ID(8) + TeamID(8) + Name(200) + CreatedAt/UpdatedAt(16) = **≈232 B**<br>Количество: 67,681 × 10 = **676,810** | **≈157 МБ** | **676,810** | **5** | **50** |
| **files** | Состав: ID(8) + ProjectID(8) + Name(200) + FileSize(8) + StorageURL(300) + CreatedAt/UpdatedAt(16) = **≈556 B**<br>Количество: 260,000,000 файлов | **≈145 ГБ** | **260,000,000** | **150** (создание) | **447** (открытие) + **149** (список) = **596** |
| **file_versions** | Состав: ID(8) + FileID(8) + VersionNumber(4) + StorageURL(300) + FileSize(8) + CreatedAt(8) = **≈336 B**<br>Количество: 2,600,000,000 версий | **≈874 ГБ** | **2,600,000,000** | **150** | **447** |
| **file_access** | Состав: FileID(8) + UserID(8) + AccessType(20) + CreatedAt(8) = **≈44 B**<br>Количество: 260M × 2.5 = **650,000,000** | **≈29 ГБ** | **650,000,000** | **50** | **596** |
| **document_body** | Состав: FileID(8) + YAMLData(средний размер 2 МБ) = **≈2 МБ**<br>Количество: 260,000,000 файлов | **≈520 ТБ** | **260,000,000** | **150** (создание) | **447** (открытие) |
| **document_resources** | Состав: FileID(8) + ResourceID(8) + ResourceURL(300) + ResourceType(50) = **≈366 B**<br>Количество: 260M × 10 ресурсов = **2,600,000,000** | **≈951 ГБ** | **2,600,000,000** | **1,500** | **4,470** |
| **document_diffs** | Состав: DiffID(8) + FileID(8) + TransactionID(8) + DiffData(500) = **≈524 B**<br>Количество: (9,323 RPS × 86400 × 30 дней) = **≈24.2 млрд** | **≈12.7 ТБ** | **24,200,000,000** | **27,969** (пик) | **9,323** (чтение для синхронизации) |
| **document_snapshots** | Состав: SnapshotID(8) + FileID(8) + TransactionID(8) + StorageURL(300) = **≈324 B**<br>Количество: 260M × 10 снапшотов = **2,600,000,000** | **≈842 ГБ** | **2,600,000,000** | **150** | **447** |
| **document_transactions** | Состав: TransactionID(8) + FileID(8) + SnapshotID(8) + CreatedAt(8) = **≈32 B**<br>Количество: (9,323 RPS × 86400 × 30 дней) = **≈24.2 млрд** | **≈774 ГБ** | **24,200,000,000** | **27,969** | **9,323** |
| **operations** | Состав: ID(8) + FileID(8) + UserID(8) + TransactionID(8) + OperationType(50) + OperationData(500) + IsComment(1) + CommentData(500) = **≈1,067 B**<br>Количество: (9,323 + 372) RPS × 86400 × 30 дней = **≈25.1 млрд** | **≈26.8 ТБ** | **25,100,000,000** | **29,085** (пик: операции + комментарии) | **9,695** (чтение для синхронизации) |
| **static_assets** | Состав: AssetID(8) + AssetURL(300) + AssetType(50) + CDNURL(300) = **≈658 B**<br>Количество: ~100,000 ассетов | **≈66 МБ** | **100,000** | **10** | **500** |
| **user_sessions** | Состав: SessionID(256) + UserID(8) + ExpiresAt(8) + CreatedAt(8) = **≈280 B**<br>Количество: 4.3M DAU × 1.5 сессий = **6,450,000** активных сессий | **≈1.8 ГБ** | **6,450,000** | **50** | **500** (проверка сессий) |

### **Требования к консистентности**

| Таблица | Консистентность | Обоснование |
|---------|-----------------|-------------|
| **users** | Strong | Критично для безопасности |
| **teams, team_members** | Strong | Управление правами доступа |
| **projects, files** | Strong | Метаданные должны быть консистентны |
| **file_versions** | Strong | История версий критична |
| **file_access** | Strong | Права доступа должны быть актуальны |
| **document_body, document_resources** | Strong | Тело документа должно быть консистентно |
| **document_diffs, document_snapshots, document_transactions** | Eventual | Дифы и снапшоты могут реплицироваться с задержкой |
| **operations** | Eventual | Операции и комментарии могут быть применены с небольшой задержкой |
| **static_assets** | Eventual | Статика кэшируется в CDN, может быть устаревшей |
| **user_sessions** | Session | Достаточна консистентность в рамках сессии |



## **6. Физическая схема БД**

![Физическая схема БД](db-physical.png)

### **Выбор СУБД**

| Таблица | СУБД | Обоснование |
|---------|------|----------------|
| **users, teams, team_members, projects, files, file_versions, file_access** | PostgreSQL | Реляционные данные требуют транзакций и сложных JOIN-запросов (например, проверка прав доступа с объединением file_access и users). PostgreSQL отлично справляется с такими запросами благодаря индексам и оптимизатору. |
| **document_body, document_resources** | Ceph (S3) | Большие файлы (YAML структура, ресурсы) хранятся в Object Storage |
| **document_diffs, document_snapshots, document_transactions** | Ceph (S3) | Дифы и снапшоты хранятся как файлы в Object Storage, метаданные в PostgreSQL |
| **operations** | Apache Cassandra | Операции редактирования и комментарии объединены. Критично низкая задержка записи — Cassandra позволяет писать локально в каждом регионе. Высокая нагрузка (29,085 QPS пик) требует горизонтального масштабирования. **Проверка:** Cassandra может обработать 24+ млрд операций — по бенчмаркам одна нода обрабатывает до 10,000 записей/сек, при 9 нодах × 3 региона = 27 нод, итого до 270,000 записей/сек, что покрывает 29,085 QPS с запасом. |
| **static_assets** | CDN + PostgreSQL | Метаданные в PostgreSQL, сами файлы в CDN |
| **user_sessions** | Redis | Быстрый доступ, TTL для автоматического удаления |

### **Индексы**

| База данных | Таблица | Индексы | Обоснование |
|-------------|---------|---------|-----------|
| **PostgreSQL** | users | `CREATE INDEX idx_users_email ON users(email);`<br>`CREATE INDEX idx_users_session ON user_sessions(session_id);` | Поиск по email при авторизации, проверка сессий |
| **PostgreSQL** | files | `CREATE INDEX idx_files_project_id ON files(project_id);`<br>`CREATE INDEX idx_files_created_at ON files(created_at DESC);` | Поиск файлов в проекте, сортировка по дате |
| **PostgreSQL** | file_versions | `CREATE INDEX idx_file_versions_file_id ON file_versions(file_id, version_number DESC);` | Получение версий файла |
| **PostgreSQL** | file_access | `CREATE INDEX idx_file_access_file_user ON file_access(file_id, user_id);` | Проверка прав доступа |
| **Cassandra** | operations | `PRIMARY KEY ((file_id), transaction_id, operation_id)` | Партиционирование по file_id, сортировка по transaction_id (не по timestamp, чтобы избежать конфликтов) |
| **PostgreSQL** | document_transactions | `CREATE INDEX idx_transactions_file_snapshot ON document_transactions(file_id, snapshot_id, transaction_id);` | Поиск транзакций относительно снапшота |
| **PostgreSQL** | document_diffs | `CREATE INDEX idx_diffs_file_transaction ON document_diffs(file_id, transaction_id);` | Поиск дифов по файлу и транзакции |

### **Шардирование**

| Таблица | Подход |
|---------|--------|
| **files** | Шардирование по `project_id` при помощи Citus |
| **file_versions** | Шардирование по `file_id` при помощи Citus |
| **file_access** | Шардирование по `file_id` при помощи Citus |
| **document_diffs, document_snapshots, document_transactions** | Шардирование по `file_id` при помощи Citus |
| **operations** | Автошардирование (Cassandra) по `file_id` |

### **Резервирование**

| Таблица | Схема резервирования |
|---------|----------------------|
| **PostgreSQL** | Master-Slave с 2 репликами на шард |
| **Cassandra** | Запись происходит локально в ближайшем регионе , что дает меньшую задержку при записи в удаленный мастер. При отказе одной ноды в регионе система продолжает работать . При полном отказе региона данные доступны из других регионов с небольшой задержкой. |
| **Redis** | Master-Slave с автоматическим аварийным переключением |

### **Схема резервного копирования**

| База данных | Частота |
|-------------|---------|
| **PostgreSQL** | Backup 1×/день  |
| **Cassandra** | Snapshots 1×/день |
| **Redis** | snapshot каждые 6 часов + команды, изменяющие данные каждую секунду |


## **7. Алгоритмы**

| Алгоритм | Область применения | Обоснование |
|----------|-------------------|-----------|
| **CRDT (Conflict-free Replicated Data Types)** | Реалтайм-коллаборация и синхронизация | **Выбранный алгоритм.** Обеспечивает консистентность при одновременном редактировании без центрального координатора. Операции применяются локально и автоматически конвергируют к одному состоянию. Критично для снижения задержки — операции применяются без ожидания подтверждения от сервера. Работает идеально с распределенной архитектурой, где запись происходит в разных регионах. |
| **Snapshot + Diffs (Git-подобная модель)** | Хранение и восстановление документов | Документ хранится как снапшот (полное состояние) + последовательность дифов (изменений). Снапшоты создаются периодически по ID транзакции. Для восстановления: берем снапшот + применяем все дифы после транзакции снапшота. Это позволяет быстро восстановить любое состояние документа без хранения всех версий целиком. |
| **Transaction-based ordering** | Разрешение конфликтов | Используем ID транзакции вместо timestamp для определения порядка операций. Это решает проблему конфликтов при одновременном редактировании — каждая операция получает уникальный transaction_id, который определяет точку относительно снапшота. |
| **Lazy Loading** | Загрузка элементов холста | Загружаются только видимые элементы и элементы вблизи viewport, что ускоряет открытие файлов. Критично для UX — пользователь видит файл почти мгновенно. |



## **8. Технологии**

| Технология | Область применения | Обоснование |
|------------|-------------------|---------------------|
| **Golang** | Backend | Компилируемый язык с высокой производительностью и отличной поддержкой конкурентности (goroutines). Идеален для обработки большого количества WebSocket-соединений (69,924 RPS пик) и операций редактирования. Альтернативы (Node.js, Python) имеют проблемы: Node.js — callback hell и проблемы с CPU-bound задачами, Python — GIL ограничивает параллелизм. Go дает низкую задержку и эффективное использование ресурсов, что критично для low latency requirement. |
| **TypeScript + React** | Frontend | TypeScript обеспечивает типобезопасность, React — эффективный рендеринг UI. Виртуальный DOM оптимизирует обновления интерфейса при частых изменениях состояния. |
| **WebSocket** | Реалтайм-коллаборация | Двусторонняя связь критична для реалтайм-коллаборации. Альтернативы (HTTP long polling, Server-Sent Events) добавляют задержку из-за overhead на установку соединения. WebSocket устанавливается один раз и поддерживает низкую задержку передачи операций, что критично для синхронизации курсоров и изменений между пользователями. |
| **NGINX** | L7 балансировка нагрузки, прокси | SSL-терминация, обратное проксирование, кэширование метаданных. Высокая производительность для обработки HTTP/WebSocket трафика (8,000 RPS на инстанс). Принимаем трафик сразу на L7 без L4, так как NGINX справляется с нагрузкой. Статика отдается через CDN, NGINX обрабатывает только динамические запросы. |
| **Kubernetes** | Оркестрация | Автоматическое масштабирование сервисов критично для обработки пиковых нагрузок. HPA позволяет масштабировать под нагрузкой без ручного вмешательства, что критично для SaaS с переменной нагрузкой. Альтернативы (Docker Swarm, ручное управление) требуют ручного масштабирования, что приводит к простоям при всплесках нагрузки или перерасходу ресурсов в спокойное время. |
| **PostgreSQL** | Основная база данных | Реляционная СУБД с поддержкой транзакций, сложных запросов и индексов. Критично для метаданных файлов и пользователей, где нужны JOIN'ы (например, проверка прав доступа: file_access JOIN users). Альтернативы (MongoDB, Cassandra) не подходят — нет транзакций или сложных запросов. PostgreSQL обеспечивает ACID-гарантии, что критично для финансовых операций и прав доступа. |
| **Apache Cassandra** | Хранение операций и комментариев | Ключевая фишка Cassandra — возможность локальной записи в каждом регионе с `LOCAL_QUORUM`, что критично для low latency requirement. Альтернатива (PostgreSQL с мастером в одном регионе) добавила бы 50-150 мс задержки для пользователей из других регионов, что неприемлемо для реалтайм-редактора. Горизонтальное масштабирование и высокая пропускная способность записи (29,085 QPS пик) делают Cassandra оптимальным выбором. **Проверка производительности:** По бенчмаркам одна нода Cassandra обрабатывает до 10,000 записей/сек. При 9 нодах × 3 региона = 27 нод, итого до 270,000 записей/сек, что покрывает 29,085 QPS с большим запасом. |
| **CDN (Cloudflare / AWS CloudFront)** | Отдача статики и защита от DDoS | Статика (JS/CSS бандлы, ассеты) составляет до 70% трафика. NGINX может не справиться с пиковыми нагрузками, особенно при DDoS. CDN решает обе проблемы: разгружает NGINX и обеспечивает защиту на уровне edge-нод. Кэширование на edge-серверах по всему миру снижает задержку загрузки для пользователей. |
| **Redis** | Кэш и сессии | Быстрое хранилище в памяти для кэширования метаданных файлов и хранения активных сессий. Задержка <1 мс критична для проверки сессий на каждом запросе (500 QPS чтения). Альтернативы (Memcached, in-memory cache) либо не имеют персистентности, либо менее функциональны. Redis с TTL идеален для сессий — автоматическое удаление истекающих сессий без дополнительной логики. |
| **Ceph (S3)** | Хранение файлов | S3-совместимое хранилище с горизонтальным масштабированием и отказоустойчивостью. Объем данных огромен (7.3 ПБ), требуется распределенное хранилище. Технология CRUSH автоматически перераспределяет данные при добавлении нод. Альтернативы (локальные диски, NFS) не масштабируются и создают single point of failure. Ceph обеспечивает репликацию 3× и автоматическое восстановление при отказе нод. |
| **Kafka** | Асинхронный обмен данными | Используется для передачи событий между сервисами (создание версий, индексация для поиска). Высокая пропускная способность и гарантированная доставка сообщений. |
| **Prometheus** | Мониторинг | Сбор метрик сервисов, поддержка alerting, интеграция с Kubernetes. |
| **Grafana** | Мониторинг | Построение дашбордов по метрикам, аналитика и гибкая настройка уведомлений. Интеграция с Prometheus. |



## **9. Обеспечение надежности**

| Компонент | Схема резервирования |
|-----------|---------------------|
| **Backend сервисы (Go)** | **N+1** — Управляется через Kubernetes с автоматическим перезапуском подов при сбоях |
| **NGINX (L7 балансировщик)** | **N+1** — Вне Kubernetes; Health-check'и для исключения неработающих бэкендов. Распределение по 3 зонам доступности |
| **PostgreSQL** | **Primary–Replica (Patroni) с 2 репликами** — одна синхронная, одна асинхронная; автоматический failover. **PgBouncer** для пуллинга подключений. Ежедневный backup + WAL ≤ 15 мин |
| **Cassandra** | **Replication Factor = 3**, каждая запись хранится на 3 нодах. Snapshots 1×/день |
| **Redis** | **Master-Slave с Sentinel** — автоматический failover при отказе мастера |
| **Ceph** | **Репликация 3× (CRUSH)** — автоматическое распределение реплик по нодам |
| **Kafka** | **Replication Factor = 3** — каждая партиция хранится на трех брокерах |
| **Kubernetes** | **Автоматический перезапуск подов** при падении контейнеров. **Horizontal Pod Autoscaler (HPA)** для масштабирования под нагрузкой |



## **10. Схема проекта**

![Схема проекта](project-schema.svg)

### **Описание сервисов**

| Сервис | Назначение |
|:--|:--|
| **Auth_Service** | Управление пользователями: регистрация, авторизация, управление сессиями. Расположен в Нью-Йорке (мастер). |
| **File_Service** | Управление метаданными файлов и проектов: создание, список, права доступа. Расположен в Нью-Йорке (мастер) для создания файлов, в СПб для работы с БД. |
| **Editor_Collab_Service** | Объединенный сервис для редактирования, коллаборации, комментариев и операций. Обрабатывает операции редактирования, управляет WebSocket-соединениями, broadcast операций между пользователями, синхронизацию через CRDT, комментарии. Расположен в региональных ДЦ (Нью-Йорк, Франкфурт, СПб). |
| **Version_Service** | Управление версиями файлов: создание снапшотов по ID транзакции, восстановление версий через снапшот + дифы. Расположен в региональных ДЦ. |
| **DB_Service** | Сервис для работы с PostgreSQL. Расположен в СПб рядом с базой данных для минимальной задержки. |

### **Потоки данных**

#### **Открытие файла**
1. Client → **CDN** (статичные ассеты: JS/CSS) → отдача из edge-кэша 
2. Client → **L7 (NGINX)** → **File_Service** [Auth] → проверка прав доступа через DB_Service в СПб
3. **File_Service** → **DB_Service (СПб)** → получение метаданных файла из PostgreSQL
4. **File_Service** → **Ceph (S3)** в регионе → получение последнего снапшота файла
5. **File_Service** → **Cassandra** в регионе → получение всех дифов после снапшота
6. Client получает снапшот + дифы, применяет их локально через CRDT
7. Client устанавливает WebSocket-соединение с **Editor_Collab_Service** в локальном регионе
8. Client отправляет свой текущий transaction_id серверу для синхронизации

#### **Редактирование файла**

**Алгоритм репликации:**

1. Client → **Editor_Collab_Service** (WebSocket) → отправка операции с текущим transaction_id клиента
2. **Editor_Collab_Service** → генерирует новый transaction_id для операции
3. **Editor_Collab_Service** → применяет операцию локально через CRDT (без ожидания сервера)
4. **Editor_Collab_Service** → **Cassandra (operations) в локальном регионе** → сохранение операции с transaction_id и `LOCAL_QUORUM` (задержка <5 мс)
5. **Editor_Collab_Service** → broadcast операции всем подключенным пользователям файла в регионе через WebSocket
6. Клиенты получают операцию и применяют её через CRDT относительно своей текущей позиции (transaction_id)
7. **Клиент получает изменения относительно позиции x:** 
   - Клиент отправляет серверу свой текущий transaction_id (позиция x)
   - Сервер отправляет все операции с transaction_id > x
   - Клиент применяет их последовательно через CRDT
   - Это гарантирует, что клиент получит все пропущенные операции при переподключении
8. Асинхронно: **Cassandra** реплицирует операцию в другие регионы
9. При получении операции из другого региона: клиент применяет её через CRDT, если transaction_id больше текущего

**Работа с зависимыми файлами:**
- Если файл использует ресурсы из другого файла (например, компонент из библиотеки), при открытии файла загружаются метаданные зависимых файлов
- Ресурсы (изображения, шрифты) загружаются по требованию через CDN

#### **Создание снапшота**
1. **Version_Service** → периодически (каждые 100 операций или раз в час) создает снапшот
2. **Version_Service** → получает текущее состояние файла через CRDT (применяет все дифы к последнему снапшоту)
3. **Version_Service** → сохраняет снапшот в **Ceph (S3)** в формате YAML
4. **Version_Service** → сохраняет метаданные в **PostgreSQL (document_snapshots)** с transaction_id
5. При восстановлении версии: берем снапшот по transaction_id + применяем все дифы после этой транзакции



## **11. Список серверов**

### **Конфигурации технологий**

| Технология | Характер сервиса | RPS (на инстанс) | RAM (на инстанс) |
|------------|------------------|------------------|------------------|
| **CDN** | Отдача статики, защита от DDoS | Неограничено (edge-ноды) | — |
| **NGINX L7** | L7-балансер | 8,000 | 500 МБ |
| **Go (WebSocket)** | Реалтайм-коллаборация | 1,000 соединений/ядро | 200 МБ/ядро |
| **Go (CRUD)** | Метаданные | 3,500 RPS/ядро | 100 МБ/ядро |
| **PostgreSQL** | Метаданные | 100 QPS/ядро | 18 ГБ/реплика |
| **Cassandra** | Операции и комментарии (локальная запись + чтение) | 1,400 QPS/ядро (запись), 2,800 QPS/ядро (чтение) | 6 ГБ/нода |
| **Ceph (S3)** | Хранение файлов, снапшотов, дифов | — | — |

### **Расчет количества серверов (на примере Нью-Йорка, редактирование)**

#### Определение нагрузки
- **API-запросы**: `170 + 170 = 340 RPS`
- **WebSocket-соединения**: `26,570 RPS` (подключения)
- **Операции записи**: `10,625 RPS`
- **ИТОГО**: `37,535 RPS`

#### NGINX L7
- **Нагрузка**: `37,535 RPS`
- Производительность: **8,000 RPS** на инстанс
- Целевая загрузка: **70%** (U = 0.7)
- Запас: **30%** (S = 1.3)
- Расчет: `N = ⌈(37,535 × 1.3) / (8,000 × 0.7)⌉ = ⌈48,796 / 5,600⌉ = ⌈8.71⌉ = 9`
- С учетом отказоустойчивости и 3 зон доступности: **12 инстансов NGINX L7** (4 в каждой AZ)

#### Go-сервисы (K8s Pods)

| Сервис | RPS | CPU (ядер) | RAM (ГБ) | Replicas | Replicas/AZ |
|--------|-----|------------|----------|----------|-------------|
| **Auth_Service** (Нью-Йорк) | 50 | 1 | 0.1 | 3 | 1 |
| **File_Service** (Нью-Йорк + СПб) | 596 | 1 | 0.1 | 3 | 1 |
| **Editor_Collab_Service** (регионы) | 29,085 | 85 | 17 | 15 | 5 |
| **Version_Service** (регионы) | 150 | 1 | 0.2 | 3 | 1 |
| **DB_Service** (СПб) | 1,200 | 12 | 2.4 | 3 | 1 |

### **Итоговая таблица: серверы по регионам**

| Регион | L7 | Auth | File | Editor_Collab | Version | DB_Service |
|--------|----|------|------|---------------|---------|-------------|
| **Нью-Йорк** (мастер) | 2 | 3 | 3 | — | — | — |
| **Нью-Йорк** (редактирование) | 12 | — | — | 15 | 3 | — |
| **Франкфурт** (редактирование) | 10 | — | — | 12 | 3 | — |
| **СПб** (редактирование) | 10 | — | — | 13 | 3 | — |
| **СПб** (БД) | — | — | — | — | — | 3 |

**Примечание:** Расчеты для Франкфурта и СПб выполнены аналогично Нью-Йорку на основе их RPS (29,670 и 31,582 соответственно).

### **Хранилища**

| Хранилище | Объём | QPS |
|-----------|-------|-----|
| PostgreSQL | 1.1 ТБ | 1,200 |
| Ceph | 7.3 ПБ + 520 ТБ (document_body) + 12.7 ТБ (diffs) + 842 ГБ (snapshots) = **~7.84 ПБ** | 28,000 |
| Cassandra | 26.8 ТБ (operations) | 29,085 |
| Redis | 1.8 ГБ | 500 |

### **Конфигурации узлов хранилищ**

| Название | Хостинг | Конфигурация | Ядра | Количество | Покупка |
|----------|---------|--------------|-------|-----|---------|
| **PostgreSQL** | own/bare metal | 1×EPYC 7543 / 256GB RAM / 4×NVMe 3.8TB / 2×25GbE | 32 | 4 | €7,200 |
| **Ceph (на регион)** | own/bare metal | 2×EPYC 7443 / 128GB RAM / 12×HDD 18TB + 4×NVMe 1.6TB / 2×100GbE | 48 | 86 | €13,000 |
| **Cassandra** | own/bare metal | 1×EPYC 7443 / 128GB RAM / 2×NVMe 1.6TB / 2×25GbE | 24 | 9 | €7,500 |
| **Redis** | own/bare metal | 1×EPYC 7443 / 64GB RAM / 1×NVMe 1.6TB / 2×10GbE | 24 | 3 | €3,200 |



## **Источники**
1.  **Figma Legal — Data Processing Addendum (DPA):**  
    [https://www.figma.com/legal/dpa/  ](https://www.figma.com/legal/dpa/  )  

2.  **Figma Blog — 2025 AI Report:**  
    [https://www.figma.com/blog/figma-2025-ai-report-perspectives/  ](https://www.figma.com/blog/figma-2025-ai-report-perspectives/  )  
    
3.  **Enlyft — Companies using Figma:**  
    [https://enlyft.com/tech/products/figma  ](https://enlyft.com/tech/products/figma  )  
  
4.  **SQ Magazine — Figma Statistics 2025:**  
    [https://sqmagazine.co.uk/figma-statistics/  ](https://sqmagazine.co.uk/figma-statistics/  )  
    
5.  **Exploding Topics — Most Visited Websites:**  
    [https://explodingtopics.com/blog/most-visited-websites  ](https://explodingtopics.com/blog/most-visited-websites  )  
  



